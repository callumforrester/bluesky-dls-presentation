{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bluesky\n",
    "\n",
    "- A collection of Python libraries for analysis-friendly data collection\n",
    "- Also, confusingly, the name of one of those libraries \n",
    "- Developed by NSLS-II since 2015\n",
    "\n",
    "\n",
    "### Useful links:\n",
    "- [Github](https://github.com/bluesky/)\n",
    "- [High Level Documentation](https://nsls-ii.github.io/)\n",
    "- [Tutorial](https://nsls-ii.github.io/bluesky/tutorial.html)\n",
    "- [DLS Demo on P47 Test Rig](https://dlsltd-my.sharepoint.com/:f:/g/personal/callum_forrester_diamond_ac_uk/EoCVYM1VtpdHrltBQYQ7ePkBYhyhRSt_pmJsDxpHEcoF5Q?e=MOCEdX)\n",
    "\n",
    "\n",
    "## Components\n",
    "\n",
    "![architecture](block-diagram.png \"Architecture\")\n",
    "\n",
    "Decouples a number of components, separated by well-defined interfaces. You can swap out any of these with a new library obeying the interfaces.\n",
    "\n",
    "| Library     | Purpose                                                | Analogous DLS Components              | Github                                   |\n",
    "|-------------|--------------------------------------------------------|---------------------------------------|------------------------------------------|\n",
    "| Ophyd       | Device Management                                      | GDA Scannables, Devices, Detectors    | https://github.com/bluesky/ophyd         |\n",
    "| Bluesky     | Orchestration, Sequencing, Exporting Collection Events | GDA Scannables, Scans, Jython Scripts | https://github.com/bluesky/bluesky       |\n",
    "| DataBroker  | Event Collection/Aggregation, I/O-agnostic Data Access | Dawn Data Server, NeXus Files         | https://github.com/bluesky/databroker    |\n",
    "| Suitcase    | Data Export Plugins for DataBroker                     | GDA Nexus Writer                      | https://github.com/bluesky/suitcase-core |\n",
    "| Event Model | Formal Structure for Events                            | Possibly the DIAD acquisition model   | https://github.com/bluesky/event-model   |\n",
    "\n",
    "\n",
    "## Interfaces\n",
    "\n",
    "Documentation: https://nsls-ii.github.io/ophyd/architecture.html\n",
    "\n",
    "![uml](uml.png \"UML\")\n",
    "\n",
    "Note, Python typing means NSLS-II are now foramlly defining these interfaces in the code, see PR [#1446](https://github.com/bluesky/bluesky/pull/1446).\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "- Each `Readable` device exports data as JSON, it can also export references to data, for example a detector can export a reference to an HDF5 file.\n",
    "- The `RunEngine` exports events (conforming to the Event Model) that include this data, plus various metadata.\n",
    "- DataBroker captures and aggregates these events for later access. \n",
    "- Optionally, any suitcase plugins for DataBroker will write the data to the user's desired format (NSLS-II are not NeXus fanatics like us). \n",
    "\n",
    "\n",
    "## Plans\n",
    "\n",
    "- Recipes for sequences of actions (which usually export events)\n",
    "- Normally written as Python \"yield\" functions but can be any iterable of Bluesky `Msg`s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `RunEngine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluesky import RunEngine\n",
    "\n",
    "RE = RunEngine()\n",
    "\n",
    "# Simplest possible plan:\n",
    "RE([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluesky import Msg\n",
    "from pprint import pprint\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def show_events(name: str, doc: Dict[str, Any]) -> None:\n",
    "    pprint({name: doc})\n",
    "\n",
    "\n",
    "RE([Msg(\"open_run\"), Msg(\"close_run\")], show_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Yield Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plan():\n",
    "    yield Msg(\"open_run\")\n",
    "    yield Msg(\"close_run\")\n",
    "\n",
    "# Lazy generator\n",
    "my_plan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaulates to the same as the plan above\n",
    "list(my_plan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces same behavoir from RunEngine\n",
    "RE(my_plan(), show_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bluesky.plan_stubs as bps\n",
    "import bluesky.plans as bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_run():\n",
    "    yield from bps.open_run()\n",
    "    yield from bps.sleep(3)\n",
    "    yield from bps.close_run()\n",
    "\n",
    "RE(empty_run(), show_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "from ophyd import EpicsMotor\n",
    "\n",
    "# Device wrapping ADSIM motor, need to set EPICS dummy ports and use machine hostname\n",
    "os.environ[\"EPICS_CA_SERVER_PORT\"] = \"6064\"\n",
    "os.environ[\"EPICS_CA_REPEATER_PORT\"] = \"6065\"\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "\n",
    "x = EpicsMotor(name=\"x\", prefix=f\"{hostname}-MO-SIM-01:M1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.wait_for_connection()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.set(x.position + 1).wait()\n",
    "x.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Heirarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ophyd import MotorBundle, Component as Cpt\n",
    "\n",
    "class SimBundle(MotorBundle):\n",
    "    \"\"\"\n",
    "    ADSIM EPICS motors\n",
    "    \"\"\"\n",
    "\n",
    "    x: EpicsMotor = Cpt(EpicsMotor, \"M1\")\n",
    "    y: EpicsMotor = Cpt(EpicsMotor, \"M2\")\n",
    "    z: EpicsMotor = Cpt(EpicsMotor, \"M3\")\n",
    "    theta: EpicsMotor = Cpt(EpicsMotor, \"M4\")\n",
    "    load: EpicsMotor = Cpt(EpicsMotor, \"M5\")\n",
    "\n",
    "motors = SimBundle(name=\"motors\", prefix=f\"{hostname}-MO-SIM-01:\")\n",
    "motors.wait_for_connection()\n",
    "\n",
    "[component.dotted_name for component in motors.walk_components()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(bps.mvr(motors.x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(bps.mvr(\n",
    "    motors.x, 1,\n",
    "    motors.y, -1\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector\n",
    "\n",
    "- Tree of components, top level components are the driver and plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ophyd import DetectorBase, SingleTrigger\n",
    "from ophyd.areadetector.cam import AreaDetectorCam\n",
    "from ophyd.areadetector.plugins import HDF5Plugin, PosPlugin, StatsPlugin\n",
    "from ophyd.areadetector.filestore_mixins import FileStoreHDF5, FileStoreIterativeWrite\n",
    "\n",
    "DATA_ROOT: str = \"/tmp\"\n",
    "DATA_WRITE_PATH_TEMPLATE: str = \"%Y\"\n",
    "\n",
    "\n",
    "class AdSimDetector(SingleTrigger, DetectorBase):\n",
    "    class HDF5File(HDF5Plugin, FileStoreHDF5, FileStoreIterativeWrite):\n",
    "        pool_max_buffers = None\n",
    "        file_number_sync = None\n",
    "        file_number_write = None\n",
    "\n",
    "        def get_frames_per_point(self):\n",
    "            return self.parent.cam.num_images.get()\n",
    "\n",
    "    cam: AreaDetectorCam = Cpt(AreaDetectorCam, suffix=\"CAM:\")\n",
    "    stat: StatsPlugin = Cpt(StatsPlugin, suffix=\"STAT:\")\n",
    "    pos: PosPlugin = Cpt(PosPlugin, suffix=\"POS:\")\n",
    "    hdf: HDF5File = Cpt(\n",
    "        HDF5File,\n",
    "        suffix=\"HDF5:\",\n",
    "        root=DATA_ROOT,\n",
    "        write_path_template=DATA_WRITE_PATH_TEMPLATE,\n",
    "    )\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.hdf.kind = \"normal\"\n",
    "\n",
    "        self.stage_sigs = {\n",
    "            # Setup the plugin chain\n",
    "            self.stat.nd_array_port: self.cam.port_name.get(),\n",
    "            self.hdf.nd_array_port: self.cam.port_name.get(),\n",
    "            \n",
    "            # Setup Driver\n",
    "            self.cam.array_counter: 0,\n",
    "            self.cam.image_mode: \"Multiple\",\n",
    "            self.cam.trigger_mode: \"Internal\",\n",
    "            \n",
    "            **self.stage_sigs\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def hints(self) -> Dict[str, Any]:\n",
    "        return {\"fields\": \"sum\"}\n",
    "    \n",
    "    def describe(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"sum\": {\n",
    "                \"source\": self.stat.sum.name,\n",
    "                \"dtype\": \"number\",\n",
    "                \"shape\": [],\n",
    "                \"units\": \"count\"\n",
    "            }\n",
    "            **super().describe()\n",
    "        }\n",
    "\n",
    "    def read(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"sum\": self.stat.sum.value,\n",
    "            **super().read()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = AdSimDetector(name=\"adsim\", prefix=f\"{hostname}-AD-SIM-01:\")\n",
    "det.wait_for_connection()\n",
    "\n",
    "# Make sure the plugin is primed\n",
    "#det.hdf.warmup()\n",
    "\n",
    "# Set transient values to how we want them\n",
    "RE(bps.mv(\n",
    "    det.cam.num_images, 1, \n",
    "    det.cam.acquire_time, 0.1, \n",
    "    det.cam.acquire_period, 0.11))\n",
    "\n",
    "\n",
    "# Give it a directory to write data\n",
    "if not os.path.exists(f\"{DATA_ROOT}/2021\"):\n",
    "    os.mkdir(f\"{DATA_ROOT}/2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(bp.count([det]), show_events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4  ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "bb1b4e13c62ad6ea215d2182fe3cbbd39b530f2fc55535c18cc4719ce432ee30"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}